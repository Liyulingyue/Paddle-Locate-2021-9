{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 方案说明\n",
    "本方案是一个简单的根据0基础入门的示例中的识别手写数字改写而成的黄斑定位程序。<br />\n",
    "本方案从头到尾直接运行即可，整体布局为 **数据获取 -> 函数定义 -> 训练 -> 预测**。<br />\n",
    "\n",
    "# 题目分析\n",
    "## 难点<br />\n",
    "&ensp;&ensp;题目要求为在一组图片上找到黄斑中心，但是图片的大小不一，每张图片对应的黄斑中心的取值范围也随着图片大小的变化而变化，从而缺乏一个统一的标准。\n",
    "    \n",
    "## 解决方案<br />\n",
    "&ensp;&ensp;指定缩放尺寸，将所有的图片均缩放到指定尺寸。对于中心点坐标，将所有的中心点坐标转化为中心点在xy轴的百分比位置，如目标点在最中间则认为横纵分别为0.5。最后再将预测后的小数还原为整数即可得到真实图片上的像素点坐标。\n",
    "\n",
    "## 具体实现策略<br />\n",
    "&ensp;&ensp;（本程序没有实现异步读取，直接做了最基础的读数据，运行。最后会在./work/Fovea_Localization_Results.csv中保存测试结果。）<br />\n",
    "&ensp;&ensp;1. 依次读取训练图片，将图片转为灰度模式，将图片缩放到指定尺寸，将黄斑中心转化到[0,1]。直接使用dataframe记录图片信息和黄斑中心分别作为输入和输出。<br />\n",
    "&ensp;&ensp;2. 构造神经网络，这部分直接参考0基础入门的示例中的识别手写数字。[https://www.paddlepaddle.org.cn/tutorials/projectdetail/2182025]<br />\n",
    "&ensp;&ensp;3. 训练数据，将之前保存过的dataframe转化为tensor直接训练即可，本程序将xy坐标分开进行训练。<br />\n",
    "&ensp;&ensp;4. 依次读取测试图片，将图片转为灰度模式，将图片缩放到指定尺寸。直接使用dataframe记录图片信息和原始图片尺寸，原始图片尺寸用于将预测结果转化为真实坐标。<br />\n",
    "&ensp;&ensp;5. 预测，并将预测后的值转化到真实坐标上。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 程序开始\n",
    "## 获取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 下载数据\r\n",
    "import urllib \r\n",
    "import requests   \r\n",
    "import os\r\n",
    "url = 'https://bj.bcebos.com/v1/dataset-bj/%E5%8C%BB%E7%96%97%E6%AF%94%E8%B5%9B/%E5%B8%B8%E8%A7%84%E8%B5%9B%EF%BC%9APALM%E7%9C%BC%E5%BA%95%E5%BD%A9%E7%85%A7%E4%B8%AD%E9%BB%84%E6%96%91%E4%B8%AD%E5%A4%AE%E5%87%B9%E5%AE%9A%E4%BD%8D.zip'  \r\n",
    "\r\n",
    "if not os.path.exists('./work/Train_and_test.zip'):\r\n",
    "    print(\"Downloading start!\")\r\n",
    "    urllib.request.urlretrieve(url, \"./work/Train_and_test.zip\")  \r\n",
    "    print(\"Downloading end!\")\r\n",
    "else:\r\n",
    "    print(\"Already Downloading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 解压数据\r\n",
    "! unzip -oq ./work/Train_and_test.zip -d ./work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 定义（包，变量，函数）<br />\n",
    "\n",
    "自定义变量包括:<br />\n",
    "&ensp;&ensp;image_size \t\t # 缩放图片的大小<br />\n",
    "&ensp;&ensp;m_ite\t   \t\t# 训练的迭代次数，相当于基础教程里的epoch<br />\n",
    "&ensp;&ensp;model_save_dir\t # 训练后的模型保存地址<br />\n",
    "\n",
    "自定义函数包括:<br />\n",
    "&ensp;&ensp;get_train_image\t\t读取训练图片，缩放图片到指定大小<br />\n",
    "&ensp;&ensp;get_test_image\t\t读取测试图片，缩放图片到指定大小<br />\n",
    "&ensp;&ensp;Mymodel\t\t\t\t定义CNN网络<br />\n",
    "&ensp;&ensp;train\t\t\t\t对网络进行训练<br />\n",
    "&ensp;&ensp;test\t\t\t\t对网络进行测试并且写入.csv<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle\r\n",
    "import paddle.nn.functional as F\r\n",
    "import os\r\n",
    "import numpy as np\r\n",
    "from paddle.nn import Conv2D, MaxPool2D, Linear\r\n",
    "import pandas as pd\r\n",
    "from PIL import Image\r\n",
    "import random\r\n",
    "\r\n",
    "# 定义缩放的大小，训练迭代次数，模型保存目录\r\n",
    "global image_size\r\n",
    "image_size = 96\r\n",
    "m_ite=500\r\n",
    "model_save_dir='./work/mymodel'\r\n",
    "last_model_dir='./work/mymodel'\r\n",
    "\r\n",
    "def get_train_image(image_size):\r\n",
    "    pd.set_option('mode.chained_assignment', None)\r\n",
    "    # 读xlsx\r\n",
    "    df = pd.read_excel('./work/常规赛：PALM眼底彩照中黄斑中央凹定位/Train/Fovea_Location_train.xlsx')\r\n",
    "    # 定义变量用于保存图片的原始大小和修改后的中心点坐标\r\n",
    "    df['ori_width'] = 0\r\n",
    "    df['ori_height'] = 0\r\n",
    "    df['changed_x'] = 0.0\r\n",
    "    df['changed_y'] = 0.0\r\n",
    "    im_list = []\r\n",
    "    for i in range(len(df)):  # df[df.columns[0]]:\r\n",
    "        if i % 50 == 0:\r\n",
    "            print(str(i / len(df) * 100) + '% finished')\r\n",
    "        im = Image.open('./work/常规赛：PALM眼底彩照中黄斑中央凹定位/Train/fundus_image/' + df[df.columns[0]][i])\r\n",
    "        df['ori_width'][i] = np.array(im).shape[1]  # 列对应横向宽度，行对应纵向宽度\r\n",
    "        df['ori_height'][i] = np.array(im).shape[0]\r\n",
    "        df['changed_x'][i] = df['Fovea_X'][i]/np.array(im).shape[1]\r\n",
    "        df['changed_y'][i] = df['Fovea_Y'][i]/np.array(im).shape[0]\r\n",
    "        #转化为灰度图并缩小，保存在列表中\r\n",
    "        im = im.convert('L')\r\n",
    "        im = im.resize((image_size, image_size), Image.ANTIALIAS)\r\n",
    "        im = np.array(im).reshape(1, -1).astype(np.float32)\r\n",
    "        im_list.append(im.tolist()[0])\r\n",
    "    print(str(1 * 100) + '% finished')\r\n",
    "    im_record = np.array(im_list)\r\n",
    "    df2 = pd.DataFrame(im_record)\r\n",
    "    pd.set_option('mode.chained_assignment', \"raise\")\r\n",
    "    # return train_infor, train_input\r\n",
    "    # 返回图片的标签信息和图片向量\r\n",
    "    return df, df2\r\n",
    "\r\n",
    "def get_test_image(image_size):\r\n",
    "    # read the test_infor\r\n",
    "    mylist=[]\r\n",
    "    im_list = []\r\n",
    "    for i in range(400):\r\n",
    "        if i % 50 == 0:\r\n",
    "            print(str(i / 400 * 100) + '% finished')\r\n",
    "        target_pic_name='T' + ('%04d' % (i+1)) + '.jpg'\r\n",
    "        # 无法直接从csv中读取，所以手动生成向量\r\n",
    "        tmplist=[target_pic_name,0.0,0.0,0,0,0.0,0.0]\r\n",
    "        im = Image.open('./work/常规赛：PALM眼底彩照中黄斑中央凹定位/PALM-Testing400-Images/' + target_pic_name)\r\n",
    "        tmplist[3] = np.array(im).shape[1]  # 列对应横向宽度，行对应纵向宽度\r\n",
    "        tmplist[4] = np.array(im).shape[0]\r\n",
    "        im = im.convert('L')\r\n",
    "        im = im.resize((image_size, image_size), Image.ANTIALIAS)\r\n",
    "        im = np.array(im).reshape(1, -1).astype(np.float32)\r\n",
    "        im_list.append(im.tolist()[0])\r\n",
    "\r\n",
    "        mylist.append(tmplist)\r\n",
    "    print(str(1 * 100) + '% finished')\r\n",
    "    test_df = pd.DataFrame.from_records(mylist, columns=['FileName', 'Fovea_X', 'Fovea_Y', 'ori_width', 'ori_height', 'changed_x', 'changed_y'])\r\n",
    "    im_record = np.array(im_list)\r\n",
    "    df_test_input = pd.DataFrame(im_record)\r\n",
    "    pd.set_option('mode.chained_assignment', \"raise\")\r\n",
    "    # return test_infor, test_input\r\n",
    "    return test_df, df_test_input\r\n",
    "\r\n",
    "#定义模型，本模型参考了https://www.paddlepaddle.org.cn/tutorials/projectdetail/2182025\r\n",
    "class Mymodel(paddle.nn.Layer):\r\n",
    "    def __init__(self):\r\n",
    "        super(Mymodel, self).__init__()\r\n",
    "        global image_size\r\n",
    "        # 定义卷积层，输出特征通道out_channels设置为20，卷积核的大小kernel_size为5，卷积步长stride=1，padding=2\r\n",
    "        self.conv1 = Conv2D(in_channels=1, out_channels=20, kernel_size=5, stride=1, padding=2)\r\n",
    "        # 定义池化层，池化核的大小kernel_size为2，池化步长为2\r\n",
    "        self.max_pool1 = MaxPool2D(kernel_size=2, stride=2)\r\n",
    "        # 定义卷积层，输出特征通道out_channels设置为20，卷积核的大小kernel_size为5，卷积步长stride=1，padding=2\r\n",
    "        self.conv2 = Conv2D(in_channels=20, out_channels=20, kernel_size=5, stride=1, padding=2)\r\n",
    "        # 定义池化层，池化核的大小kernel_size为2，池化步长为2\r\n",
    "        self.max_pool2 = MaxPool2D(kernel_size=2, stride=2)\r\n",
    "        # 定义全连接层，输出维度是2\r\n",
    "        # 计算维度\r\n",
    "        tmp=np.zeros([image_size,image_size], dtype='float32', order='C')\r\n",
    "        tmp = np.array(tmp).reshape(1, 1, image_size, image_size).astype(np.float32)\r\n",
    "        tmp=paddle.to_tensor(tmp)\r\n",
    "        tmp1 = self.conv1(tmp)\r\n",
    "        tmp2 = self.max_pool1(tmp1)\r\n",
    "        tmp3 = self.conv2(tmp2)\r\n",
    "        tmp4 = self.max_pool2(tmp3)\r\n",
    "        liner_input_num=1\r\n",
    "        for i in range(len(tmp4.shape)):\r\n",
    "            liner_input_num*=tmp4.shape[i]\r\n",
    "        self.fc = Linear(in_features=liner_input_num, out_features=5000)\r\n",
    "        self.fc2 = Linear(in_features=5000, out_features=1000)\r\n",
    "        self.fc3 = Linear(in_features=1000, out_features=1)\r\n",
    "\r\n",
    "    # 定义网络前向计算过程，卷积后紧接着使用池化层，最后使用全连接层计算最终输出\r\n",
    "    def forward(self, inputs):\r\n",
    "         x = self.conv1(inputs)\r\n",
    "         x = F.relu(x)\r\n",
    "         x = self.max_pool1(x)\r\n",
    "         x = self.conv2(x)\r\n",
    "         x = F.relu(x)\r\n",
    "         x = self.max_pool2(x)\r\n",
    "         x = paddle.reshape(x, [x.shape[0], -1])\r\n",
    "         x = self.fc(x)\r\n",
    "         x = F.relu6(x)\r\n",
    "         x =self.fc2(x)\r\n",
    "         x = F.tanh(x)\r\n",
    "         x =self.fc3(x)\r\n",
    "         return x\r\n",
    "\r\n",
    "# 定义训练\r\n",
    "def train(model1,model2, train_infor, train_input,eval_infor,eval_input,image_size,m_ite):\r\n",
    "    # 将数据转化为四维矩阵格式，并归一到0-1\r\n",
    "    train_im = paddle.to_tensor(train_input.values.astype('float32')/255)\r\n",
    "    train_im = paddle.reshape(train_im,[train_im.shape[0], 1, image_size, image_size])\r\n",
    "    train_lab_x = train_infor[['changed_x']]\r\n",
    "    train_lab_x = paddle.to_tensor(train_lab_x.values.astype('float32'))\r\n",
    "    train_lab_y = train_infor[['changed_y']]\r\n",
    "    train_lab_y = paddle.to_tensor(train_lab_y.values.astype('float32'))\r\n",
    "\r\n",
    "    eval_im = paddle.to_tensor(eval_input.values.astype('float32')/255)\r\n",
    "    eval_im = paddle.reshape(eval_im,[eval_im.shape[0], 1, image_size, image_size])\r\n",
    "    eval_lab_x = eval_infor[['changed_x']]\r\n",
    "    eval_lab_x = paddle.to_tensor(eval_lab_x.values.astype('float32'))\r\n",
    "    eval_lab_y = eval_infor[['changed_y']]\r\n",
    "    eval_lab_y = paddle.to_tensor(eval_lab_y.values.astype('float32'))\r\n",
    "\r\n",
    "    # 定义学习器\r\n",
    "    opt1 = paddle.optimizer.Adam(learning_rate=0.001, weight_decay=paddle.regularizer.L2Decay(coeff=1e-5),\r\n",
    "                                parameters=model1.parameters())\r\n",
    "    opt2 = paddle.optimizer.Adam(learning_rate=0.001, weight_decay=paddle.regularizer.L2Decay(coeff=1e-5),\r\n",
    "                                parameters=model2.parameters())\r\n",
    "\r\n",
    "    print('init train!')\r\n",
    "    \r\n",
    "    best_loss_x=1000\r\n",
    "    best_loss_y=1000\r\n",
    "    best_x_ite=-1\r\n",
    "    best_y_ite=-1\r\n",
    "\r\n",
    "    # 训练\r\n",
    "    for i in range(m_ite):\r\n",
    "        predicts1 = model1(train_im)\r\n",
    "        predicts2 = model2(train_im)\r\n",
    "        loss1 = F.square_error_cost(predicts1, train_lab_x)\r\n",
    "        loss2 = F.square_error_cost(predicts2, train_lab_y)\r\n",
    "        avg_loss1 = paddle.mean(loss1)\r\n",
    "        avg_loss2 = paddle.mean(loss2)\r\n",
    "\r\n",
    "        avg_loss1.backward()\r\n",
    "        avg_loss2.backward()\r\n",
    "        opt1.step()\r\n",
    "        opt1.clear_grad()\r\n",
    "        opt2.step()\r\n",
    "        opt2.clear_grad()\r\n",
    "        \r\n",
    "        model1.eval()\r\n",
    "        model2.eval()\r\n",
    "\r\n",
    "        predictsx = model1(eval_im)\r\n",
    "        predictsy = model2(eval_im)\r\n",
    "        lossx = F.square_error_cost(predictsx, eval_lab_x)\r\n",
    "        lossy = F.square_error_cost(predictsy, eval_lab_y)\r\n",
    "        avg_lossx = paddle.mean(lossx)\r\n",
    "        avg_lossy = paddle.mean(lossy)\r\n",
    "        \r\n",
    "        if avg_lossx.numpy()<best_loss_x:\r\n",
    "            best_loss_x=avg_lossx.numpy()\r\n",
    "            paddle.save(model1.state_dict(), model_save_dir+'x')\r\n",
    "            best_x_ite=i\r\n",
    "        if avg_lossy.numpy()<best_loss_y:\r\n",
    "            best_loss_y=avg_lossy.numpy()\r\n",
    "            paddle.save(model2.state_dict(), model_save_dir+'y')\r\n",
    "            best_y_ite=i\r\n",
    "        \r\n",
    "        model1.train()\r\n",
    "        model2.train()\r\n",
    "        \r\n",
    "        if i%100==0:\r\n",
    "            print(\"ite: {}, x los: {}, y los: {}, best x ite: {}, best y ite: {}\".format(i,avg_loss1.numpy(),avg_loss2.numpy(),best_x_ite,best_y_ite))\r\n",
    "\r\n",
    "#定义测试\r\n",
    "def test(model1, model2, test_infor, test_input ,image_size):\r\n",
    "    print('test_start')\r\n",
    "    # param_dict = paddle.load('./PALM')\r\n",
    "    # model.load_dict(param_dict)\r\n",
    "    \r\n",
    "    model1.eval()\r\n",
    "    model2.eval()\r\n",
    "\r\n",
    "    test_im = paddle.to_tensor(test_input.values.astype('float32')/255)\r\n",
    "    test_im = paddle.reshape(test_im,[test_im.shape[0], 1, image_size, image_size])\r\n",
    "    predicts1 = model1(test_im)\r\n",
    "    predicts1 = predicts1.numpy()\r\n",
    "    predicts2 = model2(test_im)\r\n",
    "    predicts2 = predicts2.numpy()\r\n",
    "\r\n",
    "    pd.set_option('mode.chained_assignment', None)\r\n",
    "\r\n",
    "    #将预测的点还原为图片上的坐标\r\n",
    "    for i in range(400):\r\n",
    "        test_infor['changed_x'][i]=predicts1[i][0]\r\n",
    "        test_infor['changed_y'][i]=predicts2[i][0]\r\n",
    "        test_infor['Fovea_X'][i] = predicts1[i][0]*test_infor['ori_width'][i]\r\n",
    "        test_infor['Fovea_Y'][i] = predicts2[i][0]*test_infor['ori_height'][i]\r\n",
    "    pd.set_option('mode.chained_assignment', 'raise')\r\n",
    "    \r\n",
    "    #写文件\r\n",
    "    final_df=test_infor[['FileName','Fovea_X','Fovea_Y']]\r\n",
    "    final_df.to_csv('./work/Fovea_Localization_Results.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 正式进行训练和测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#获得训练数据\r\n",
    "print(\"get_train_image!\")\r\n",
    "train_infor, train_input=get_train_image(image_size)\r\n",
    "print(\"train infor gotten!\")\r\n",
    "\r\n",
    "train_infor.to_csv('train_infor.csv',index=None)\r\n",
    "train_input.to_csv('train_input.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_infor=pd.read_csv('train_infor.csv')\r\n",
    "train_input=pd.read_csv('train_input.csv')\r\n",
    "\r\n",
    "train_num=len(train_infor)\r\n",
    "eval_percent=0.2;\r\n",
    "cut_point=int(train_num*eval_percent)\r\n",
    "\r\n",
    "index=list(range(train_num))\r\n",
    "random.shuffle(index)\r\n",
    "\r\n",
    "eval_infor=train_infor.iloc[index[:cut_point],:]\r\n",
    "eval_input=train_input.iloc[index[:cut_point],:]\r\n",
    "train_infor=train_infor.iloc[index[cut_point:],:]\r\n",
    "train_input=train_input.iloc[index[cut_point:],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 根据测试，如果目标得到最优xy而非对样本的无尽拟合，200次迭代足够了\r\n",
    "m_ite=200\r\n",
    "\r\n",
    "#构造模型开始训练\r\n",
    "model1 = Mymodel()\r\n",
    "model2 = Mymodel()\r\n",
    "print(\"model created\")\r\n",
    "train(model1,model2,train_infor, train_input,eval_infor,eval_input,image_size, m_ite)\r\n",
    "print(\"train finish\")\r\n",
    "paddle.save(model1.state_dict(), model_save_dir+str(1))\r\n",
    "paddle.save(model2.state_dict(), model_save_dir+str(2))\r\n",
    "print(\"model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_infor, test_input=get_test_image(image_size)\r\n",
    "test_infor.to_csv('test_infor.csv',index=None)\r\n",
    "test_input.to_csv('test_input.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#开始测试\r\n",
    "model1 = Mymodel()\r\n",
    "model2 = Mymodel()\r\n",
    "print(\"model created\")\r\n",
    "param_dict1 = paddle.load(last_model_dir+'x')\r\n",
    "model1.load_dict(param_dict1)\r\n",
    "param_dict2 = paddle.load(last_model_dir+'y')\r\n",
    "model2.load_dict(param_dict2)\r\n",
    "\r\n",
    "test(model1,model2, test_infor, test_input ,image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 总结和一些讨论\n",
    "相对于之前的工作增加了验证集，并且将xy分开进行处理，但是提升的效果仍为有限，可见想要提高效果从网络结构下手更好。\n",
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
